{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision\n",
    "import kornia.augmentation as K\n",
    "import kornia.feature as F\n",
    "import sys\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import mido\n",
    "from mido import MidiFile, MidiTrack, Message\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['.ipynb_checkpoints', 'quake2.mid', 'Untitled.ipynb']\n",
      "quake2.mid\n"
     ]
    }
   ],
   "source": [
    "print(os.listdir(os.getcwd()))\n",
    "# select quake2.mid\n",
    "f_name = list(filter(lambda x: x == 'quake2.mid', os.listdir(os.getcwd())))\n",
    "if len(f_name) <= 0:\n",
    "    raise RuntimeError('no file name specified')\n",
    "elif isinstance(f_name, list):\n",
    "        f_name = f_name[0]\n",
    "\n",
    "print(f_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_notes = 96\n",
    "samples_per_measure = 96\n",
    "\n",
    "def midi_to_samples(fname):\n",
    "\thas_time_sig = False\n",
    "\tflag_warning = False\n",
    "\tmid = MidiFile(fname)\n",
    "\tticks_per_beat = mid.ticks_per_beat\n",
    "\tticks_per_measure = 4 * ticks_per_beat\n",
    "\n",
    "\tfor i, track in enumerate(mid.tracks):\n",
    "\t\tfor msg in track:\n",
    "\t\t\tif msg.type == 'time_signature':\n",
    "\t\t\t\tnew_tpm = msg.numerator * ticks_per_beat * 4 / msg.denominator\n",
    "\t\t\t\tif has_time_sig and new_tpm != ticks_per_measure:\n",
    "\t\t\t\t\tflag_warning = True\n",
    "\t\t\t\tticks_per_measure = new_tpm\n",
    "\t\t\t\thas_time_sig = True\n",
    "\tif flag_warning:\n",
    "\t\tprint(\"  ^^^^^^ WARNING ^^^^^^\")\n",
    "\t\tprint(\"    \" + fname )\n",
    "\t\tprint(\"    Detected multiple distinct time signatures.\")\n",
    "\t\tprint(\"  ^^^^^^ WARNING ^^^^^^\")\n",
    "\t\treturn []\n",
    "\t\n",
    "\tall_notes = {}\n",
    "\tfor i, track in enumerate(mid.tracks):\n",
    "\t\tabs_time = 0\n",
    "\t\tfor msg in track:\n",
    "\t\t\tabs_time += msg.time\n",
    "\t\t\tif msg.type == 'note_on':\n",
    "\t\t\t\tif msg.velocity == 0:\n",
    "\t\t\t\t\tcontinue\n",
    "\t\t\t\tnote = msg.note - (128 - num_notes)/2\n",
    "\t\t\t\tassert(note >= 0 and note < num_notes)\n",
    "\t\t\t\tif note not in all_notes:\n",
    "\t\t\t\t\tall_notes[note] = []\n",
    "\t\t\t\telse:\n",
    "\t\t\t\t\tsingle_note = all_notes[note][-1]\n",
    "\t\t\t\t\tif len(single_note) == 1:\n",
    "\t\t\t\t\t\tsingle_note.append(single_note[0] + 1)\n",
    "\t\t\t\tall_notes[note].append([abs_time * samples_per_measure / ticks_per_measure])\n",
    "\t\t\telif msg.type == 'note_off':\n",
    "\t\t\t\tif len(all_notes[note][-1]) != 1:\n",
    "\t\t\t\t\tcontinue\n",
    "\t\t\t\tall_notes[note][-1].append(abs_time * samples_per_measure / ticks_per_measure)\n",
    "\tfor note in all_notes:\n",
    "\t\tfor start_end in all_notes[note]:\n",
    "\t\t\tif len(start_end) == 1:\n",
    "\t\t\t\tstart_end.append(start_end[0] + 1)\n",
    "\tsamples = []\n",
    "\tfor note in all_notes:\n",
    "\t\tfor start, end in all_notes[note]:\n",
    "\t\t\tsample_ix = int(start / samples_per_measure)\n",
    "\t\t\twhile len(samples) <= sample_ix:\n",
    "\t\t\t\tsamples.append(np.zeros((samples_per_measure, num_notes), dtype=np.uint8))\n",
    "\t\t\tsample = samples[sample_ix]\n",
    "\t\t\tstart_ix = start - sample_ix * samples_per_measure\n",
    "\t\t\tif False:\n",
    "\t\t\t\tend_ix = min(end - sample_ix * samples_per_measure, samples_per_measure)\n",
    "\t\t\t\twhile start_ix < end_ix:\n",
    "\t\t\t\t\tsample[start_ix, note] = 1\n",
    "\t\t\t\t\tstart_ix += 1\n",
    "\t\t\telse:\n",
    "\t\t\t\tsample[start_ix, note] = 1\n",
    "\treturn samples\n",
    "\n",
    "def samples_to_midi(samples, fname, ticks_per_sample, thresh=0.5):\n",
    "\tmid = MidiFile()\n",
    "\ttrack = MidiTrack()\n",
    "\tmid.tracks.append(track)\n",
    "\tticks_per_beat = mid.ticks_per_beat\n",
    "\tticks_per_measure = 4 * ticks_per_beat\n",
    "\tticks_per_sample = ticks_per_measure / samples_per_measure\n",
    "\tabs_time = 0\n",
    "\tlast_time = 0\n",
    "\tfor sample in samples:\n",
    "\t\tfor y in xrange(sample.shape[0]):\n",
    "\t\t\tabs_time += ticks_per_sample\n",
    "\t\t\tfor x in xrange(sample.shape[1]):\n",
    "\t\t\t\tnote = x + (128 - num_notes)/2\n",
    "\t\t\t\tif sample[y,x] >= thresh and (y == 0 or sample[y-1,x] < thresh):\n",
    "\t\t\t\t\tdelta_time = abs_time - last_time\n",
    "\t\t\t\t\ttrack.append(Message('note_on', note=note, velocity=127, time=delta_time))\n",
    "\t\t\t\t\tlast_time = abs_time\n",
    "\t\t\t\tif sample[y,x] >= thresh and (y == sample.shape[0]-1 or sample[y+1,x] < thresh):\n",
    "\t\t\t\t\tdelta_time = abs_time - last_time\n",
    "\t\t\t\t\ttrack.append(Message('note_off', note=note, velocity=127, time=delta_time))\n",
    "\t\t\t\t\tlast_time = abs_time\n",
    "\tmid.save(fname)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def midi_to_pianoroll(f_name, **kwargs):\n",
    "    '''\n",
    "    f_name: filename as string\n",
    "    \n",
    "    - note\n",
    "    - type\n",
    "    - velocity\n",
    "    - track (with label) -> doesn't really matter we want to split these into seperate pianoroll samples\n",
    "     - TODO: important! update to 3d convolutions across tracks pretty early (after temporal convolution)\n",
    "    kwargs: dict of attributes that should be stacked into the pianoroll\n",
    "            these should be midiattr object that can have a multiplicative konstant\n",
    "    '''\n",
    "    attrs = kwargs['attrs']\n",
    "    attr_indices = dict([(key, index) for index, key in enumerate(attrs.keys())]) # dict of attr index pairs allow access to tensor index by passing message.type\n",
    "    \n",
    "    tempo = mido.bpm2tempo(kwargs['sampling_tempo'])\n",
    "    midi = MidiFile(f_name)\n",
    "    t_s  = midi.length\n",
    "    \n",
    "    ticks_per_beat = midi.ticks_per_beat\n",
    "    numerator = 4\n",
    "    denominator = 4\n",
    "    \n",
    "    T = len(midi.tracks)\n",
    "    A = len(attrs)\n",
    "    all_messages = [track for track in midi]\n",
    "    n = 0\n",
    "    times_list = []\n",
    "    all_messages.sort(key=lambda message: message.time)\n",
    "    for message in all_messages:\n",
    "        if message.is_meta:\n",
    "            #print(f'metamessage: {message}')\n",
    "            if message.type == 'end_of_track':\n",
    "                print(f'end_of_track at: {message.time}')\n",
    "            if message.type == 'set_tempo':\n",
    "                print(f'tempo: {message.tempo}')\n",
    "                tempo = message.tempo\n",
    "            if message.type == 'time_signature':\n",
    "                numerator = message.numerator\n",
    "                denominator = message.denominator        \n",
    "        times_list.append(message.time)\n",
    "        try: \n",
    "            n = max(n, message.time)\n",
    "        except:\n",
    "            pass\n",
    "        \n",
    "    ticks_per_measure = numerator * ticks_per_beat\n",
    "    print(f'time_sig: {numerator}/{denominator}')\n",
    "    plt.plot(times_list)\n",
    "    plt.show()\n",
    "    \n",
    "    # calculate how long a measure is in seconds\n",
    "    measure_duration_s = mido.tick2second(ticks_per_measure, ticks_per_beat, tempo)\n",
    "    print(measure_duration_s)\n",
    "    \n",
    "    # calculate number of measures by dividing total length by measure length (both in seconds)\n",
    "    n = int(np.ceil(t_s / measure_duration_s))\n",
    "    print(f'total measures in song: {n}')\n",
    "    \n",
    "    S_t = torch.zeros(size=(int(T), int(A), 96 * n, 96))\n",
    "    print(f'S_T.shape: {S_t.shape}')\n",
    "    \n",
    "    for t, track in enumerate(midi.tracks):\n",
    "        \n",
    "        active_notes = torch.zeros(96) #logs current activation of note at y using a float mask\n",
    "        # used as mask that sweeps over sample tensor while get messages in the order they are played            \n",
    "        abs_time = 0.\n",
    "        #A = len(midi.message types)\n",
    "        #n = total ticks / ticks_per_measure \n",
    "        # basically turns song into long ass 3d tensor [][][]....[][] of n * (96 x 96 x T) cubes\n",
    "        # note that the sample tensor will be rather sparse with a lot of zeros in their volume\n",
    "        \n",
    "        print(f'track[{t}]: {track}')\n",
    "        for m, message in enumerate(track):\n",
    "            if str(message.type) in attrs:\n",
    "                '''\n",
    "                try:\n",
    "                    pos_y = message.pos\n",
    "                except:\n",
    "                    print(f'the midi attribute {message} (time attribute != time position in track, which is pos) was marked as interesting yet has no timing information')\n",
    "                    print('this currently just puts the attribute at y = 0')\n",
    "                    pos_y = 0\n",
    "                '''\n",
    "                pos_x = abs_time / 96 #mido.second2tick(message.time, ticks_per_beat, sampling_tempo) // 96\n",
    "                pos_x = int(pos_x)\n",
    "                #print(f'pos_x : {pos_x}')\n",
    "                pos_y = message.note - (128 - num_notes)/2\n",
    "                pos_y = int(pos_y)\n",
    "                #print(f'm[{m}]: {message}')\n",
    "                if message.velocity == 0:\n",
    "                    continue\n",
    "                note = message.note - (128 - num_notes)/2\n",
    "                #assert(note >= 0 and note < num_notes)\n",
    "                attr_idx = attr_indices[message.type]\n",
    "                #print(f'attr_idx: {attr_idx}')\n",
    "                S_t[t, attr_idx, pos_x, pos_y] = float(message.velocity) / 128. \n",
    "                abs_time += message.time\n",
    "    \n",
    "    t, a, x, y = S_t.shape\n",
    "    n = x // 96\n",
    "    S_t = S_t.view((n, t, a, 96, y))\n",
    "    mask = S_t.mean(dim=(1, 2, 3, 4)) > 0.0 # mask stack elements that dont show any activation\n",
    "    keep = mask.sum() # number of stacks to keep\n",
    "    print(f'kept {keep} of {n} measures')\n",
    "    print(f'mask: {mask}')\n",
    "    mask = mask.repeat_interleave(t*a*96*y)\n",
    "    #print(S_t.view(-1).shape)\n",
    "    #print(mask.shape)\n",
    "    #print(torch.masked_select(t.view(-1), mask).view(keep, 3, 10, 10).shape)\n",
    "    \n",
    "    return torch.masked_select(S_t.view(-1), mask).view(keep, t, a, 96, y)\n",
    "\n",
    "    # uncomment when stable!!\n",
    "    #return torch.tensor(torch.masked_select(S_t.view(-1), mask).view(keep, t, a, 96, y), names=(\"Measure\", \"Track\", \"Atrribute\", \"time\", \"pitch\"))\n",
    "\n",
    "                \n",
    "        #print(f'track:{track}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "tempo: 476190\n",
      "end_of_track at: 1.8849187500000002\n",
      "time_sig: 4/4\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.9047600000000002\n",
      "total measures in song: 33\n",
      "S_T.shape: torch.Size([10, 3, 3168, 96])\n",
      "track[0]: <midi track 'var1.mid' 8 messages>\n",
      "track[1]: <midi track 'Bass' 903 messages>\n",
      "track[2]: <midi track 'Hits' 179 messages>\n",
      "track[3]: <midi track 'Hits Oct' 91 messages>\n",
      "track[4]: <midi track 'Lo Square' 270 messages>\n",
      "track[5]: <midi track 'Hi Square' 270 messages>\n",
      "track[6]: <midi track 'Loop' 390 messages>\n",
      "track[7]: <midi track 'kick' 234 messages>\n",
      "track[8]: <midi track 'Hihats' 1033 messages>\n",
      "track[9]: <midi track 'Clap' 102 messages>\n",
      "kept 10 of 33 measures\n",
      "mask: tensor([False, False, False,  True, False, False,  True, False, False,  True,\n",
      "         True, False, False,  True, False, False,  True, False, False,  True,\n",
      "        False, False, False,  True, False, False,  True, False, False,  True,\n",
      "        False, False, False])\n",
      "torch.Size([4, 3, 96, 96])\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'view_pianoroll' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-7-49f38bd7405d>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[0ms\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmidi_to_pianoroll\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mf_name\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mattrs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0minteresting_attrs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msampling_tempo\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m120.\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     10\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ms\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;36m4\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msum\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdim\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 11\u001b[1;33m \u001b[0mview_pianoroll\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ms\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msum\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdim\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m*\u001b[0m \u001b[1;36m255\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;31m# view 4 measures\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'view_pianoroll' is not defined"
     ]
    }
   ],
   "source": [
    "interesting_attrs = {\n",
    "    'note_on' : 1.0,\n",
    "    'polytouch': 1.0,\n",
    "    'aftertouch': 1.0,\n",
    "    #'note_off': 1.0,\n",
    "} # basically a dict that stores what attribute contributes how much to the intensities in tensor\n",
    "print('note_on' in interesting_attrs)\n",
    "\n",
    "s = midi_to_pianoroll(f_name, attrs=interesting_attrs, sampling_tempo=120.)\n",
    "print(s[0:4].sum(dim=(1)).shape)\n",
    "view_pianoroll(s[0:1].sum(dim=(1)) * 255) # view 4 measures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def musicsheet(batch_size=4, note_freq=64):\n",
    "    m = torch.zeros(4, 3, 96, 96)\n",
    "    for n in range(note_freq):\n",
    "        randx, randy = np.random.randint(96), np.random.randint(96)\n",
    "        length = np.random.randint(24)\n",
    "        a = np.random.uniform(0.5, 1.0)\n",
    "        s = np.random.uniform(0.0, a)\n",
    "        d = np.random.uniform(0.0, s)\n",
    "        randb = np.random.randint(4)\n",
    "        m[randb, 0, randx:int(randx+length), randy] = a\n",
    "        m[randb, 1, randx:int(randx+length / 3), randy] = s\n",
    "        m[randb, 2, randx:int(randx+length / 5), randy] = d\n",
    "    return m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#plt.imshow(m[0].transpose(0,2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def log_volume(t, r=None):\n",
    "    print(f'tensor shape:{t.shape}')\n",
    "    vol = np.product(t.shape[1:])\n",
    "    r_vol = vol if not r else r\n",
    "    print(f'absolute tensor volume:{vol}')\n",
    "    print(f'volume reduction:{vol / r_vol}')\n",
    "    print(f'latent space development:{str(chr(9608)) * int(20. / (vol / r_vol))}')\n",
    "    return vol"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def view_pianoroll(batch, url=None):\n",
    "    fig = plt.subplot()\n",
    "    fig.set_title(url)\n",
    "    img_grid = torchvision.utils.make_grid(batch, nrow=1)\n",
    "    fig.imshow(img_grid.transpose(0, 2), url=url)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tensor_memory(a):\n",
    "    print(a.element_size() * a.nelement())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([10, 10, 3, 96, 96])\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Invalid input shape, we expect BxCxHxW. Got: torch.Size([10, 10, 3, 96, 96])",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-31-165b61d6e8e3>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m    115\u001b[0m \u001b[1;31m#m = musicsheet()\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    116\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mm\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 117\u001b[1;33m \u001b[0mgfft\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mF\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgftt_response\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mm\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    118\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    119\u001b[0m \u001b[0mimg_grid\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtorchvision\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mutils\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmake_grid\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mm\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnrow\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\vae_composer\\lib\\site-packages\\kornia\\feature\\responses.py\u001b[0m in \u001b[0;36mgftt_response\u001b[1;34m(input, grads_mode, sigmas)\u001b[0m\n\u001b[0;32m    156\u001b[0m                         .format(type(input)))\n\u001b[0;32m    157\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m4\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 158\u001b[1;33m         raise ValueError(\"Invalid input shape, we expect BxCxHxW. Got: {}\"\n\u001b[0m\u001b[0;32m    159\u001b[0m                          .format(input.shape))\n\u001b[0;32m    160\u001b[0m     \u001b[0mgradients\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTensor\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mspatial_gradient\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgrads_mode\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: Invalid input shape, we expect BxCxHxW. Got: torch.Size([10, 10, 3, 96, 96])"
     ]
    }
   ],
   "source": [
    "\n",
    "class ComposerVAE(nn.Module):\n",
    "    \n",
    "    class MeasureCell(nn.Module):\n",
    "        ''' Auto Encoder that encodes a batch of measures for a single track into my and sig latent vectors'''\n",
    "        def __init__(self):\n",
    "            super(ComposerVAE.MeasureCell, self).__init__()\n",
    "            conv_1xnx1 = lambda n: torch.nn.Conv2d(in_channels=3, out_channels=3, kernel_size=(n, 1), stride=2)\n",
    "            \n",
    "            '''\n",
    "            self.conv_1x3x1 = conv_1xnx1(3) #needs to be stacked twice\n",
    "            self.bn_1 = torch.nn.BatchNorm2d(3, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
    "            #self.leaky_relu\n",
    "            self.conv_1x6x1 = conv_1xnx1(6) #needs to be stacked twice\n",
    "            self.conv_1x12x1 = conv_1xnx1(12) #needs to be stacked twice\n",
    "            # first spatial convolution combines a,s,d to single channel\n",
    "            self.conv_3x5x5 = torch.nn.Conv2d(in_channels=3, out_channels=1, kernel_size=(5, 5))\n",
    "            # convolution for first branch looking for melody correlations\n",
    "            self.conv_1x3x3 = torch.nn.Conv2d(in_channels=1, out_channels=1, kernel_size=(3, 3))\n",
    "            self.bn_2 = torch.nn.BatchNorm2d(1, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
    "            self.conv_1x5x5 = torch.nn.Conv2d(in_channels=1, out_channels=1, kernel_size=(5, 5))\n",
    "            '''\n",
    "            # before (measures, tracks, attributes, x, y)\n",
    "            # batch shape: (songs, measures, tracks, attributes, x, y)\n",
    "            self.conv_1x3x1 = torch.nn.\n",
    "\n",
    "            # \"Chord filters\"\n",
    "\n",
    "        def forward(self, m):\n",
    "            \n",
    "            assert m.ndim == 4 # make sure m is a batch of a * x * y measures\n",
    "            \n",
    "            #first some convolutions along the temporal(x)-Axis\n",
    "            last = log_volume(m)\n",
    "                                     #  _ _ _      _        _ _ _      _\n",
    "            m = self.conv_1x3x1(m)   # |_|_|_| -> |_| = >  |_|_|_| -> |_| \n",
    "\n",
    "            last= log_volume(m, last)\n",
    "\n",
    "            m = self.bn_1(m)         #  _ _ _      _        _ _ _ _ _ _      _\n",
    "            m = self.conv_1x3x1(m)   # |_|_|_| -> |_| = >  |_|_|_|_|_|_| -> |_|\n",
    "\n",
    "            last= log_volume(m, last)\n",
    "\n",
    "            m = self.bn_1(m)               #  _ _ _ _ _ _      _ \n",
    "            m = self.conv_1x6x1(m)         # |_|_|_|_|_|_| -> |_|\n",
    "\n",
    "            last = log_volume(m, last)     \n",
    "                                           #  _ _ _ _ _ _ _ _ _ _ _ _ \n",
    "            m = self.conv_1x12x1(m)        # |1|2|3|4|5|6|7|8|9|1|1|1|\n",
    "\n",
    "            last = log_volume(m, last)\n",
    "\n",
    "            img_grid = torchvision.utils.make_grid(m, nrow=1)\n",
    "            plt.imshow(img_grid.transpose(0, 2).detach())\n",
    "            plt.show()\n",
    "\n",
    "            # next look for some correlations in the 2d plane\n",
    "            # make sure to have extra convolutions using 'chord filters'\n",
    "            #                                               _ _ _ _ _\n",
    "            #                                                       /|  _\n",
    "            #                                                     /|/|  /|\n",
    "            #                                         _ _ _ _ _ /|/|/|       Isolate Notes normalized temporal space\n",
    "            #                                        |_|_|_|_|_|/|/|/|\n",
    "            #                                        |_|_|_|_|_|/|/|/|\n",
    "            #                                      # |_|_|_|_|_|/|/|/\n",
    "            m_branch1 = self.bn_1(m)               # |_|_|_|_|_|/|/\n",
    "            m_branch1 = self.conv_3x5x5(m_branch1) # |_|_|_|_|_|/\n",
    "\n",
    "            last = log_volume(m_branch1, last)\n",
    "\n",
    "            m_branch1 = self.bn_2(m_branch1)\n",
    "            m_branch1 = self.conv_1x3x3(m_branch1) # first convolution over spots in note space \n",
    "\n",
    "            last = log_volume(m_branch1, last)\n",
    "\n",
    "            m_branch1 = self.conv_1x5x5(m_branch1) # second convolution over spots in note space \n",
    "\n",
    "            last = log_volume(m_branch1, last)\n",
    "\n",
    "            m_branch1 = self.conv_1x5x5(m_branch1)\n",
    "\n",
    "            last = log_volume(m_branch1, last)\n",
    "            plt.imshow(m_branch1[0].transpose(0, 2).detach())\n",
    "            plt.show()\n",
    "            \n",
    "            \n",
    "    class MergerCell(nn.Module):\n",
    "        ''' AutoencoderCell that merges sampled latent vectors of MeasureCell's into my and sig latent vectors'''\n",
    "        def __init__(self):\n",
    "            super(ComposerVAE.MergerCell, self).__init__()\n",
    "            self.conv_3x3 = torch.nn.Conv2d(in_channels=1, out_channels=1, kernel_size=(3, 3))\n",
    "            \n",
    "        def forward(self, t):\n",
    "            assert t.ndim == 5 # make sure that t is a batch of s * t * m * a * x * y\n",
    "            return self.conv_3x3(t)\n",
    "            \n",
    "    def __init__(self, max_tracks=10):\n",
    "        super(ComposerVAE, self).__init__()\n",
    "        self.merger_cell = self.MergerCell()\n",
    "        self.measure_cell = self.MeasureCell()\n",
    "        \n",
    "    \n",
    "    def forward(self, s):\n",
    "        # takes a minibatch of s * m * t * x * y\n",
    "        # songs: s\n",
    "        # measures: m\n",
    "        # tracks: t\n",
    "        # length: x\n",
    "        # width: y\n",
    "        \n",
    "        # pass each track through measure cell\n",
    "        #s = s.transpose(1, 2) #switch measure and track dimension\n",
    "        mc_s = self.measure_cell(s) # sample of measure cell (batch of tracks)\n",
    "        f_s = self.merger_cell(mc_s) # merge samples for different tracks into one latent vector describing the song\n",
    "        print(f_s)\n",
    "            \n",
    "    \n",
    "model = ComposerVAE()\n",
    "measure, track, attr, x, y = s.shape\n",
    "m = s #musicsheet()\n",
    "#m = musicsheet()\n",
    "print(m.shape)\n",
    "gfft = F.gftt_response(m)\n",
    "\n",
    "img_grid = torchvision.utils.make_grid(m, nrow=2)\n",
    "view_pianoroll(m, url='m')\n",
    "'''plt.figure.set_title('m')\n",
    "plt.imshow(img_grid.transpose(0, 2))\n",
    "plt.show()'''\n",
    "\n",
    "print(f'gfft.shape:{gfft.shape}')\n",
    "fft_grid = torchvision.utils.make_grid(gfft, nrow=1)\n",
    "view_pianoroll(fft_grid, url='fft')\n",
    "'''plt.figure(title='fft')\n",
    "plt.imshow(fft_grid.transpose(0, 2))\n",
    "plt.show()'''\n",
    "\n",
    "#plt.imshow(m[0].transpose(0, 2))\n",
    "model(m)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6763664860353102"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.random.uniform(0.5, 1.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "298080"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.product((45, 72, 92))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 410,
   "metadata": {},
   "outputs": [],
   "source": [
    "attrs = {'h': 1.0, 'k': 0.5}\n",
    "s = dict([(key, index) for index, key in enumerate(attrs.keys())])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 411,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 411,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s['h']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 627,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(2)\n",
      "tensor([ True, False, False,  True])\n",
      "torch.Size([1200])\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2, 3, 10, 10])\n"
     ]
    }
   ],
   "source": [
    "t = torch.randn(4, 3, 10, 10)\n",
    "mask = t.mean(dim=(1, 2, 3)) > 0.0\n",
    "keep = mask.sum()\n",
    "print(keep)\n",
    "print(mask)\n",
    "mask = mask.repeat_interleave(3*10*10)\n",
    "print(mask.shape)\n",
    "plt.plot(mask)\n",
    "plt.show()\n",
    "print(torch.masked_select(t.view(-1), mask).view(keep, 3, 10, 10).shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "ename": "AssertionError",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-18-5a6ec4db2c37>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[1;32massert\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m8\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'daggi'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mAssertionError\u001b[0m: "
     ]
    }
   ],
   "source": [
    "assert isinstance(8, str)\n",
    "print('daggi')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class foo():\n",
    "    def \n",
    "    class bar():\n",
    "        "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
